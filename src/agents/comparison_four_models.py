#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ü§ñ COMPARACI√ìN 4 MODELOS IA REALES: DQN vs DeepDQN vs PPO vs A2C
"""

import sys
import os
import traceback

# Agregar directorio ra√≠z al path
root_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(root_dir)

# Importar dependencias
try:
    import numpy as np
    import pandas as pd
    import matplotlib
    matplotlib.use('TkAgg')  # Backend compatible con Windows
    import matplotlib.pyplot as plt
    from matplotlib.animation import FuncAnimation
    from matplotlib.widgets import Button, Slider
    from matplotlib.gridspec import GridSpec
    import matplotlib.dates as mdates
    from datetime import datetime, timedelta
    import threading
    import time
    import warnings
    warnings.filterwarnings('ignore')
    
    # Configurar estilo de matplotlib
    plt.style.use('dark_background')
    
    # Importar componentes de RL
    from stable_baselines3 import DQN, A2C, PPO
    HAS_RL = True
    print("‚úÖ Componentes de RL disponibles")
    
    # Importar nuestro sistema base
    from src.agents.ml_enhanced_system import MLEnhancedTradingSystem
    print("‚úÖ Sistema base importado")
    
except ImportError as e:
    print(f"‚ùå Error importando dependencias: {e}")
    print("‚ö†Ô∏è Aseg√∫rate de tener todas las dependencias instaladas:")
    print("pip install numpy pandas matplotlib stable-baselines3 gymnasium")
    sys.exit(1)
except Exception as e:
    print(f"‚ùå Error inesperado: {e}")
    traceback.print_exc()
    sys.exit(1)

class FourModelsComparison:
    """Comparaci√≥n de 4 modelos reales entrenados"""
    
    def __init__(self):
        print("üöÄ Inicializando comparaci√≥n de 4 modelos...")
        
        # Crear instancias independientes para cada modelo
        self.dqn_system = MLEnhancedTradingSystem(skip_selection=True)
        self.deepdqn_system = MLEnhancedTradingSystem(skip_selection=True)
        self.ppo_system = MLEnhancedTradingSystem(skip_selection=True)
        self.a2c_system = MLEnhancedTradingSystem(skip_selection=True)
        
        # Configurar cada modelo
        self._configure_systems()
        
        # Control de animaci√≥n
        self.is_playing = False
        self.speed = 1.0
        self.current_step = 50
        self.window_size = 120
        self.fig = None
        
        # Colores para cada modelo
        self.colors = {
            'DQN': '#ff6b6b',      # Rojo coral
            'DeepDQN': '#4ecdc4',  # Turquesa
            'PPO': '#45b7d1',      # Azul claro
            'A2C': '#f7b731'       # Amarillo
        }
        
    def _configure_systems(self):
        """Configurar los 4 sistemas con par√°metros espec√≠ficos"""
        
        # DQN - AGRESIVO (red simple, decisiones r√°pidas)
        self.dqn_system.algorithm_choice = "1"
        self.dqn_system.algorithm_name = "DQN"
        self.dqn_system.algorithm_class = DQN
        # Configurar espacio de acci√≥n discreto para DQN
        self.dqn_system.action_space = self.dqn_system.action_space
        self.dqn_system.model_paths = {
            "1": [
                "data/models/qdn/model.zip",
                "data/models/best_qdn/model.zip"
            ]
        }
        self.dqn_system.max_position_risk = 0.12
        self.dqn_system.stop_loss_pct = 0.015
        self.dqn_system.take_profit_pct = 0.035
        self.dqn_system.min_trade_separation = 1
        self.dqn_system.max_daily_trades = 20
        self.dqn_system.consecutive_loss_limit = 6
        
        # DeepDQN - PRECISO (red profunda, decisiones calculadas)
        self.deepdqn_system.algorithm_choice = "2"
        self.deepdqn_system.algorithm_name = "DeepDQN"
        self.deepdqn_system.algorithm_class = DQN
        # Configurar espacio de acci√≥n discreto para DeepDQN
        self.deepdqn_system.action_space = self.deepdqn_system.action_space
        self.deepdqn_system.model_paths = {
            "2": [
                "data/models/deepqdn/model.zip",
                "data/models/best_deepqdn/model.zip"
            ]
        }
        self.deepdqn_system.max_position_risk = 0.08
        self.deepdqn_system.stop_loss_pct = 0.025
        self.deepdqn_system.take_profit_pct = 0.055
        self.deepdqn_system.min_trade_separation = 2
        self.deepdqn_system.max_daily_trades = 12
        self.deepdqn_system.consecutive_loss_limit = 4
        
        # PPO - BALANCEADO (pol√≠tica optimizada) - USANDO MODELO ML REAL
        self.ppo_system.algorithm_choice = "3"
        self.ppo_system.algorithm_name = "PPO"
        self.ppo_system.algorithm_class = PPO
        # ‚úÖ CORREGIDO: Los modelos entrenados usan Discrete(2), no Box continuo
        from gymnasium import spaces
        self.ppo_system.action_space = spaces.Discrete(2)
        self.ppo_system.model_paths = {
            "3": [
                "data/models/ppo/model.zip",
                "data/models/best_ppo/best_model.zip"
            ]
        }
        self.ppo_system.max_position_risk = 0.10
        self.ppo_system.stop_loss_pct = 0.02
        self.ppo_system.take_profit_pct = 0.045
        self.ppo_system.min_trade_separation = 3
        self.ppo_system.max_daily_trades = 15
        self.ppo_system.consecutive_loss_limit = 4
        self.ppo_system.ml_weight = 0.7  # M√°s peso a ML cuando est√° disponible
        
        # A2C - CONSERVADOR (actor-critic balanceado) - USANDO MODELO ML REAL
        self.a2c_system.algorithm_choice = "4"
        self.a2c_system.algorithm_name = "A2C"
        self.a2c_system.algorithm_class = A2C
        # ‚úÖ CORREGIDO: Los modelos entrenados usan Discrete(2), no Box continuo
        self.a2c_system.action_space = spaces.Discrete(2)
        self.a2c_system.model_paths = {
            "4": [
                "data/models/a2c/model.zip",
                "data/models/best_a2c/model.zip"
            ]
        }
        self.a2c_system.max_position_risk = 0.06
        self.a2c_system.stop_loss_pct = 0.03
        self.a2c_system.take_profit_pct = 0.065
        self.a2c_system.min_trade_separation = 4
        self.a2c_system.max_daily_trades = 8
        self.a2c_system.consecutive_loss_limit = 3
        self.a2c_system.ml_weight = 0.8  # Mucho m√°s peso a ML cuando est√° disponible
        
        print("‚úÖ DQN configurado: AGRESIVO (12% risk, 1.5% SL, 3.5% TP)")
        print("‚úÖ DeepDQN configurado: PRECISO (8% risk, 2.5% SL, 5.5% TP)")
        print("‚úÖ PPO configurado: BALANCEADO (10% risk, 2% SL, 4.5% TP) - Modo t√©cnico avanzado")
        print("‚úÖ A2C configurado: CONSERVADOR (6% risk, 3% SL, 6.5% TP) - Modo t√©cnico ultra-conservador")
        
    def initialize_systems(self):
        """Inicializar los sistemas"""
        print("üîÑ Inicializando sistemas...")
        
        # Generar datos
        print("üìä Generando datos de mercado...")
        self.dqn_system.generate_market_data()
        
        # Asegurar que los indicadores t√©cnicos est√©n calculados
        print("üìä Calculando indicadores t√©cnicos...")
        self.dqn_system.data = self.dqn_system.calculate_indicators(self.dqn_system.data)
        
        # Copiar datos a otros sistemas
        self.deepdqn_system.data = self.dqn_system.data.copy()
        self.ppo_system.data = self.dqn_system.data.copy()
        self.a2c_system.data = self.dqn_system.data.copy()
        
        # Cargar modelos ML para todos los sistemas (igual que ml_enhanced_system.py)
        print("\nü§ñ Cargando modelo DQN...")
        self.dqn_system.load_ml_model()
        
        print("\nü§ñ Cargando modelo DeepDQN...")
        self.deepdqn_system.load_ml_model()
        
        print("\nü§ñ Cargando modelo PPO...")
        self.ppo_system.load_ml_model()
        
        print("\nü§ñ Cargando modelo A2C...")
        self.a2c_system.load_ml_model()
        
        # Inicializar estados
        for system in [self.dqn_system, self.deepdqn_system, 
                      self.ppo_system, self.a2c_system]:
            system.current_step = 50
            system.current_capital = system.initial_capital
            system.position_size = 0
            system.position_type = None
            system.daily_trades = 0
            system.consecutive_losses = 0
            system.last_trade_step = 0
            
            # Reinicializar arrays de seguimiento para el paso actual
            system.initialize_tracking_arrays()
            
            # Asegurar que tenemos suficientes datos
            if len(system.portfolio_values) <= system.current_step:
                system.portfolio_values.extend([system.initial_capital] * (system.current_step + 100))
            if len(system.actions) <= system.current_step:
                system.actions.extend([0] * (system.current_step + 100))
            if len(system.ml_predictions) <= system.current_step:
                system.ml_predictions.extend([0] * (system.current_step + 100))
            if len(system.technical_signals) <= system.current_step:
                system.technical_signals.extend([0] * (system.current_step + 100))
            
        print("‚úÖ Sistemas inicializados")
        
    # PPO y A2C ahora usan la misma l√≥gica est√°ndar que ml_enhanced_system.py
    # Intentan cargar modelos ML reales, y si fallan, usan an√°lisis t√©cnico est√°ndar
        
    def create_interface(self):
        """Crear interfaz gr√°fica id√©ntica a la imagen de referencia"""
        print("üé® Creando interfaz gr√°fica...")
        
        # Inicializar sistemas
        self.initialize_systems()
        
        # Crear figura con fondo negro
        self.fig = plt.figure(figsize=(20, 10), facecolor='black')
        
        # T√≠tulo principal
        self.fig.suptitle("ü§ñ COMPARACI√ìN 4 MODELOS IA REALES: QDN vs DeepQDN vs PPO vs A2C",
                         fontsize=16, color='white', y=0.98)
        
        # Grid para 4 gr√°ficos (2x2)
        gs = GridSpec(2, 2, height_ratios=[1, 1], width_ratios=[1, 1],
                     hspace=0.15, wspace=0.15)
        
        # Crear subplots
        self.axes = {}
        positions = [(0, 0), (0, 1), (1, 0), (1, 1)]
        models = ['DQN', 'DeepDQN', 'PPO', 'A2C']
        systems = [self.dqn_system, self.deepdqn_system, 
                  self.ppo_system, self.a2c_system]
        
        for (i, j), name, system in zip(positions, models, systems):
            ax = self.fig.add_subplot(gs[i, j])
            ax.set_facecolor('#1a1a1a')
            
            # Configurar estilo
            ax.grid(True, alpha=0.2, color='#333333')
            for spine in ax.spines.values():
                spine.set_color('#333333')
            ax.tick_params(colors='#888888')
            
            self.axes[name] = ax
            
        # Crear √°rea para botones
        self.button_axes = {}
        
        # Bot√≥n PLAY
        self.button_axes['play'] = plt.axes([0.40, 0.02, 0.06, 0.04])
        self.button_axes['play'].set_facecolor('#2a2a2a')
        self.buttons = {}
        self.buttons['play'] = Button(self.button_axes['play'], '‚ñ∂ PLAY', color='white')
        self.buttons['play'].on_clicked(self._on_play)
        
        # Bot√≥n PAUSE
        self.button_axes['pause'] = plt.axes([0.47, 0.02, 0.06, 0.04])
        self.button_axes['pause'].set_facecolor('#2a2a2a')
        self.buttons['pause'] = Button(self.button_axes['pause'], '‚è∏ PAUSE', color='white')
        self.buttons['pause'].on_clicked(self._on_pause)
        
        # Bot√≥n STOP
        self.button_axes['stop'] = plt.axes([0.54, 0.02, 0.06, 0.04])
        self.button_axes['stop'].set_facecolor('#2a2a2a')
        self.buttons['stop'] = Button(self.button_axes['stop'], '‚èπ STOP', color='white')
        self.buttons['stop'].on_clicked(self._on_stop)
        
        # Texto inferior
        plt.figtext(0.5, 0.02, "QDN(üöÄ AGRESIVO-ML) | DeepQDN(üéØ PRECISO-ML) | PPO(‚öñÔ∏è BALANCEADO-T√âCNICO) | A2C(üõ°Ô∏è CONSERVADOR-T√âCNICO)",
                   ha='center', color='white', fontsize=10)
        
        # Animaci√≥n
        self.animation = FuncAnimation(self.fig, self.update_plots, 
                                     interval=50, blit=False)
        
        plt.show()
        
    def _on_play(self, event):
        """Manejador del bot√≥n PLAY"""
        print("‚ñ∂Ô∏è Iniciando simulaci√≥n...")
        self.is_playing = True
        self.buttons['play'].color = '#00ff00'
        self.buttons['pause'].color = 'white'
        self.buttons['stop'].color = 'white'
        plt.draw()
        
    def _on_pause(self, event):
        """Manejador del bot√≥n PAUSE"""
        print("‚è∏Ô∏è Simulaci√≥n pausada")
        self.is_playing = False
        self.buttons['play'].color = 'white'
        self.buttons['pause'].color = '#ffff00'
        self.buttons['stop'].color = 'white'
        plt.draw()
        
    def _on_stop(self, event):
        """Manejador del bot√≥n STOP"""
        print("‚èπÔ∏è Simulaci√≥n detenida")
        self.is_playing = False
        self.current_step = 50
        self.initialize_systems()
        self.buttons['play'].color = 'white'
        self.buttons['pause'].color = 'white'
        self.buttons['stop'].color = '#ff0000'
        plt.draw()
        
    def play(self):
        """Iniciar simulaci√≥n"""
        self._on_play(None)
        
    def pause(self):
        """Pausar simulaci√≥n"""
        self._on_pause(None)
        
    def stop(self):
        """Detener y reiniciar"""
        self._on_stop(None)
        
    def update_plots(self, frame):
        """Actualizar gr√°ficos"""
        if not self.is_playing:
            return
            
        # Avanzar sistemas
        if self.current_step < len(self.dqn_system.data) - 1:
            self.step_forward()
            
            # Actualizar cada gr√°fico
            self.update_model_plot('DQN', self.dqn_system)
            self.update_model_plot('DeepDQN', self.deepdqn_system)
            self.update_model_plot('PPO', self.ppo_system)
            self.update_model_plot('A2C', self.a2c_system)
            
    def update_model_plot(self, name, system):
        """Actualizar gr√°fico de un modelo espec√≠fico"""
        ax = self.axes[name]
        ax.clear()
        
        # Configurar estilo
        ax.set_facecolor('#1a1a1a')
        ax.grid(True, alpha=0.2, color='#333333')
        for spine in ax.spines.values():
            spine.set_color('#333333')
        ax.tick_params(colors='#888888')
        
        # Datos visibles
        start = max(0, self.current_step - self.window_size)
        end = self.current_step + 1
        
        # Graficar precio
        prices = system.data['price'].iloc[start:end]
        dates = range(len(prices))
        ax.plot(dates, prices, color=self.colors[name], linewidth=1.5)
        
        # Se√±ales
        window_buys = [s - start for s in system.buy_signals if start <= s < end]
        window_sells = [s - start for s in system.sell_signals if start <= s < end]
        
        if window_buys:
            buy_prices = [system.data['price'].iloc[s + start] for s in window_buys]
            ax.scatter(window_buys, buy_prices, color='#00ff00', marker='^', s=100, zorder=5)
            for x, y in zip(window_buys, buy_prices):
                ax.text(x, y + 0.5, 'BUY', color='#00ff00', ha='center', fontsize=8)
                
        if window_sells:
            sell_prices = [system.data['price'].iloc[s + start] for s in window_sells]
            ax.scatter(window_sells, sell_prices, color='#ff0000', marker='v', s=100, zorder=5)
            for x, y in zip(window_sells, sell_prices):
                ax.text(x, y - 0.5, 'SELL', color='#ff0000', ha='center', fontsize=8)
        
        # ‚úÖ ARREGLO: Calcular portfolio value correctamente
        current_value = system.portfolio_values[self.current_step] if self.current_step < len(system.portfolio_values) else system.initial_capital
        
        # üîß CORREGIR el c√°lculo del portfolio para evitar duplicaci√≥n
        if hasattr(system, 'position_size') and system.position_size > 0:
            current_price = system.data['price'].iloc[self.current_step]
            # Capital disponible (dinero que no est√° invertido) + valor actual de la posici√≥n
            invested_amount = system.position_size * getattr(system, 'entry_price', current_price)
            available_cash = system.current_capital - invested_amount
            position_value = system.position_size * current_price
            current_value = available_cash + position_value
        else:
            current_value = system.current_capital
            
        total_return = (current_value / system.initial_capital - 1) * 100
        win_rate = (system.profitable_trades / max(system.total_trades, 1)) * 100
        
        # Informaci√≥n espec√≠fica del modelo
        model_type = ""
        if name == "DQN":
            model_type = "üöÄ AGRESIVO-ML"
        elif name == "DeepDQN":
            model_type = "üéØ PRECISO-ML"  
        elif name == "PPO":
            model_type = "‚öñÔ∏è BALANCEADO-T√âC"
        elif name == "A2C":
            model_type = "üõ°Ô∏è CONSERVADOR-T√âC"
        
        # ‚úÖ INFORMACI√ìN COMPACTA
        info_text = f"""{model_type}
Capital: ${current_value:,.0f}
P&L: ${current_value - system.initial_capital:+,.0f} ({total_return:+.1f}%)
Posici√≥n: {system.position_size}
Trades: {system.total_trades} | Win: {win_rate:.1f}%
{'üü¢ LONG' if system.position_size > 0 else '‚ö™ IDLE'}"""
        
        # Color de la caja seg√∫n P&L
        box_color = '#1a3a1a' if total_return >= 0 else '#3a1a1a'
        
        # ‚úÖ ARREGLO VISUAL: Mover panel a la esquina inferior derecha para que no se superponga
        ax.text(0.98, 0.02, info_text, transform=ax.transAxes,
                fontsize=7, color='white', va='bottom', ha='right',
                bbox=dict(facecolor=box_color, alpha=0.9, edgecolor='#333333', pad=4))
        
        # T√≠tulo con P&L
        title_color = '#00ff00' if total_return >= 0 else '#ff0000'
        ax.set_title(f"{name} - ${current_value:,.0f} ({total_return:+.1f}%)",
                    color=title_color, pad=15)  # M√°s padding para evitar superposici√≥n
        
    def step_forward(self):
        """Avanzar un paso en todos los sistemas con comportamientos diferenciados"""
        self.current_step += 1
        
        # Actualizar paso en todos los sistemas
        for system in [self.dqn_system, self.deepdqn_system, self.ppo_system, self.a2c_system]:
            system.current_step = self.current_step
        
        # DQN - Ejecutar l√≥gica completa de trading con modelo ML
        try:
            if self.dqn_system.ml_model is not None:
                state = self.dqn_system.get_state()
                action = self.dqn_system.ml_model.predict(state, deterministic=True)[0]
                self.dqn_system.step_forward()
            else:
                self.dqn_system.step_forward()
        except Exception as e:
            print(f"Error en DQN: {e}")
        
        # DeepDQN - Ejecutar l√≥gica completa de trading con modelo ML
        try:
            if self.deepdqn_system.ml_model is not None:
                state = self.deepdqn_system.get_state()
                action = self.deepdqn_system.ml_model.predict(state, deterministic=True)[0]
                self.deepdqn_system.step_forward()
            else:
                self.deepdqn_system.step_forward()
        except Exception as e:
            print(f"Error en DeepDQN: {e}")
        
        # PPO - Usar l√≥gica est√°ndar igual que ml_enhanced_system.py
        try:
            if self.ppo_system.ml_model is not None:
                state = self.ppo_system.get_state()
                action = self.ppo_system.ml_model.predict(state, deterministic=True)[0]
                self.ppo_system.step_forward()
            else:
                self.ppo_system.step_forward()
        except Exception as e:
            print(f"Error en PPO: {e}")
        
        # A2C - Usar l√≥gica est√°ndar igual que ml_enhanced_system.py
        try:
            if self.a2c_system.ml_model is not None:
                state = self.a2c_system.get_state()
                action = self.a2c_system.ml_model.predict(state, deterministic=True)[0]
                self.a2c_system.step_forward()
            else:
                self.a2c_system.step_forward()
        except Exception as e:
            print(f"Error en A2C: {e}")
    
    # Funciones step_ppo_forward y step_a2c_forward eliminadas
    # PPO y A2C ahora usan la l√≥gica est√°ndar de ml_enhanced_system.py

def main():
    """Funci√≥n principal"""
    print("\n" + "="*60)
    print("ü§ñ COMPARACI√ìN 4 MODELOS IA REALES")
    print("DQN vs DeepDQN vs PPO vs A2C")
    print("="*60 + "\n")
    
    try:
        comparison = FourModelsComparison()
        comparison.create_interface()
    except Exception as e:
        print(f"\n‚ùå Error: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    main() 